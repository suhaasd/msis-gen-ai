## Glossary

### Chain-of-thought Prompting

### Agents
Agents are autonomous or semi-autonomous AI entities that can perform tasks, make decisions, and call tools or APIs based on goals. In academic and enterprise settings, agents are often used to automate workflows like document summarization, task routing, or multi-step reasoning.


### Context window
The context window is the maximum number of tokens (words or parts of words) that an AI model can process and consider simultaneously when generating a response. It is essentially the “memory” capacity of the model during an interaction or task. Models with larger context windows can handle larger attachments/prompts/inputs and sustain “memory” of a conversation for longer.


### Large Language Model (LLM)
Neural networks known as large language models work by forecasting word sequences. Large language models’ capabilities are rapidly advancing and continue to evolve with increased use. They can now hold dialogues, write prose, and scrutinize enormous text quantities from the internet.

### Meta Prompt / System Prompt
A meta prompt, also called a system prompt, is a set of instructions provided to the AI model behind the scenes before user interaction begins. These instructions may be hidden from the user. Meta prompts set behavior, tone, or boundaries for how the AI should respond (e.g., “You are a helpful teaching assistant”).


### Prompt Engineering
Prompt engineering is the practice of designing effective prompts to guide an AI model’s output. This involves setting roles, specifying format, adding constraints, or giving examples to improve the quality, tone, or relevance of the response.


### RAG (Retrieval-Augmented Generation)
It is a method that combines a language model with external sources added by the user, such as documents, PDFs, or other materials. While language models can generate clear and human-like responses, they don’t automatically have access to this added content. RAG retrieves relevant information from those sources, allowing the model to give more accurate and grounded answers.


### Reinforcement Learning

### Temperature (AI Temperature)
Lower values (e.g., 0.2) lead to more focused and consistent answers, while higher values (e.g., 0.8) produce more varied responses.

### Token
A token is the smallest unit of text that an AI model processes and understands; this is typically 4 characters in English, or about ¾ of a word. Tokens may include whole words, parts of words, individual characters, punctuation marks, and special characters.


### Transformer Model
